{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed03c83",
   "metadata": {},
   "source": [
    "# 顔認識　サンプルソース"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8c5fb8",
   "metadata": {},
   "source": [
    "---\n",
    "**「顔認識の基礎知識」で解説したOSSライブラリを使用して、**  \n",
    "**入力した写真から特定の人物の顔を認識させるプログラムです。** \n",
    "\n",
    "---\n",
    "### **■処理に必要なライブラリをインポートします【参考：第三章】**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45c5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import face_recognition # Face recognition:顔認識\n",
    "import dlib             # Dlib:機械学習\n",
    "import cv2              # OpenCV:画像処理\n",
    "from matplotlib import pyplot as plt # 画像表示\n",
    "import time             # 処理時間計測"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c94b8",
   "metadata": {},
   "source": [
    "### **■各種パラメータを設定します【参考：第六章、第七章】**\n",
    "\n",
    "①検出モデル  \n",
    "hog:計算量は少ないですが、精度は低いです。  \n",
    "cnn:計算量は多いですが、精度は高いです。  \n",
    "\n",
    "②顔検出精度  \n",
    "数字を大きくすると精度が上がりますが、計算量も上がります。デフォルトは1です。  \n",
    "2より大きくするとマシン負荷が高くなりすぎる可能性があります。  \n",
    "\n",
    "③顔認識の閾値  \n",
    "値を低くするほど判定が厳しくなり、高くするほど判定が緩くなります。デフォルトは0.6です。  \n",
    "複数の顔がある写真の認識で、ほとんどの顔が同一となった場合、  \n",
    "この数値を調整することで、より精度の高い認識を行うことができます。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ee86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- パラメータ --------------------------------\n",
    "# 検出モデル\n",
    "MODEL = \"hog\"\n",
    "#MODEL = \"cnn\"\n",
    "\n",
    "# 顔検出精度\n",
    "UPSAMPLE = 1\n",
    "\n",
    "# 顔認識の閾値\n",
    "TOLERANCE = 0.6\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6eb3b9",
   "metadata": {},
   "source": [
    "### **■OpenCVを使って画像(顔写真)を入力します【参考：第四章】**\n",
    "\n",
    "顔認識対象の画像と顔認識させる画像の2枚を読み込みます。  \n",
    "\n",
    "OpenCV はカラーフォーマットが BGR 形式であるため、  \n",
    "一般的な RGB 形式にするためには、読み込み後に変換が必要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e8e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像ファイル読み込み\n",
    "image         = cv2.imread(r\"Photo\\family_1_papa.jpg\") # 顔認識対象の顔画像\n",
    "unknown_image = cv2.imread(r\"Photo\\family_2.jpg\")      # 顔認識させる画像\n",
    "\n",
    "# BGR→RGBに変換\n",
    "image         = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "unknown_image = cv2.cvtColor(unknown_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df40ecca",
   "metadata": {},
   "source": [
    "### **■face_recognitionを使って写真から顔を検索します【参考：第五章、第六章】**\n",
    "\n",
    "画像に写っているすべての顔を検索します。  \n",
    "指定した検出モデルとアップサンプリング回数で処理を行います。\n",
    "\n",
    "検出モデルをcnnにしたり、アップサンプリング回数を増やすと、処理に時間が掛かります。  \n",
    "完了後に処理時間が表示されます。\n",
    "\n",
    "顔を検出できなかった場合はここで終了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5696126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_locations time :0.6283204555511475[sec]\n"
     ]
    }
   ],
   "source": [
    "# 時間計測 ： 開始時刻を記録\n",
    "cp_0 = time.time() \n",
    "\n",
    "# 画像に写っているすべての顔を検索\n",
    "face_locations = face_recognition.face_locations(unknown_image, model=MODEL, number_of_times_to_upsample=UPSAMPLE)\n",
    "\n",
    "# 時間計測 ： 終了時刻を記録\n",
    "cp_1 = time.time() \n",
    "time_hog = cp_1 - cp_0 # [終了時刻 - 開始時刻] から処理時間を算出 \n",
    "print (\"face_locations time :{0}\".format(time_hog) + \"[sec]\", flush=True)\n",
    "\n",
    "# 顔を検出できなかった場合、ここで終了\n",
    "if len(face_locations) <= 0:\n",
    "    raise SystemExit(\"Face Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def588e",
   "metadata": {},
   "source": [
    "### **■face_recognitionを使って顔認識を行います【参考：第七章】**\n",
    "\n",
    "検出した顔のデータを、認識させる顔データと比較して、認識結果と認識値を出力します。  \n",
    "検出した顔が複数ある場合、すべての顔データと比較します。\n",
    "\n",
    "認識結果は True/False のいずれかで出力します。  \n",
    "認識値は 0 に近いほど顔が似ていると判断したことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d1f241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 4 face(s) in this photograph.\n",
      "[False]\n",
      "[0.70802824]\n",
      "[False]\n",
      "[0.80408018]\n",
      "[True]\n",
      "[0.39837144]\n",
      "[False]\n",
      "[0.82534138]\n"
     ]
    }
   ],
   "source": [
    "# 顔を検出できた場合、顔認識を行う\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "# 比較元の顔のエリアを指定する\n",
    "known_face_encodings = face_recognition.face_encodings(image)[0]\n",
    "\n",
    "# 検出した各顔の顔認識を行うループ\n",
    "resultslist = []\n",
    "distslist = []\n",
    "for index in range(len(face_locations)):\n",
    "\n",
    "    # 比較先の顔のエリアを指定する\n",
    "    unknown_encoding = face_recognition.face_encodings(unknown_image, face_locations)[index]\n",
    "\n",
    "    # 認識結果を出力\n",
    "    results = face_recognition.compare_faces([known_face_encodings], unknown_encoding, TOLERANCE)\n",
    "    print(results)\n",
    "    resultslist.append(results)\n",
    "\n",
    "    # 認識値を出力\n",
    "    dists = face_recognition.face_distance([known_face_encodings], unknown_encoding)\n",
    "    print(dists)\n",
    "    distslist.append(dists)\n",
    "\n",
    "    # 認識した顔の各部位を検出する\n",
    "    face_landmarks = face_recognition.face_landmarks(unknown_image, face_locations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb7bf2",
   "metadata": {},
   "source": [
    "### **■OpenCVを使って顔認識の結果を出力します【参考：第八章】**\n",
    "\n",
    "画像から検出した顔を枠で囲み、認識結果と認識値を描画します。\n",
    "\n",
    "描画後は別ウィンドウで画像を表示し、さらにファイルとして保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efcbc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 認識した結果を画像に合成するループ\n",
    "rect_color = (0, 0, 255)     # 青枠\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontsize = 0.4\n",
    "font_color = (255, 255, 255) # 白文字\n",
    "index = 0\n",
    "for top, left, bottom, right in face_locations:\n",
    "    # 顔を枠で囲む\n",
    "    cv2.rectangle(unknown_image, (left, top), (right, bottom), rect_color, thickness=2)\n",
    "\n",
    "    # 認識結果と値を描き込む\n",
    "    cv2.rectangle(unknown_image, (right - 1, bottom), (right + 140, bottom + 20), rect_color, thickness=-1)\n",
    "    cv2.putText(unknown_image, str(resultslist[index]), (right, bottom + 14), font, fontsize, font_color, 1)\n",
    "    cv2.putText(unknown_image, str(distslist[index]), (right + 50, bottom + 14), font, fontsize, font_color, 1)\n",
    "    index += 1\n",
    "\n",
    "# 画像を出力\n",
    "output_image = cv2.cvtColor(unknown_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"Photo\\output.jpg\", output_image) # 保存\n",
    "cv2.imshow(\"image\",output_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
